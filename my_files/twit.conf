tier1.sources = source1
tier1.sinks = sink1
tier1.channels = channel1

tier1.sources.source1.type = org.apache.flume.source.kafka.KafkaSource
tier1.sources.source1.kafka.bootstrap.servers = localhost:9092
tier1.sources.source1.kafka.consumer.auto.offset.reset = earliest
tier1.sources.source1.kafka.topics = my_tweets_topic
tier1.sources.source1.kafka.consumer.group.id = flume
tier1.sources.source1.interceptors = i1
tier1.sources.source1.interceptors.i1.type = timestamp
tier1.sources.source1.kafka.consumer.timeout.ms = 100
tier1.sources.source1.batchSize = 100

tier1.sinks.sink1.type = hdfs
tier1.sinks.sink1.hdfs.path = hdfs://localhost:9000/BigDataTweets/1_Avro
tier1.sinks.sink1.hdfs.fileType = DataStream
tier1.sinks.sink1.hdfs.batchSize = 1000
tier1.sinks.sink1.hdfs.rollSize = 0
tier1.sinks.sink1.hdfs.rollCount = 10000
tier1.sinks.sink1.hdfs.fileSuffix=.avro

tier1.channels.channel1.type = memory
tier1.channels.channel1.capacity = 30000
tier1.channels.channel1.transactionCapacity = 1000


tier1.sources.source1.channels = channel1
tier1.sinks.sink1.channel = channel1